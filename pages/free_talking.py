import streamlit as st
from openai import OpenAI
import os
from pathlib import Path
from audiorecorder import audiorecorder
from pydub import AudioSegment
from pydub.playback import play
from io import BytesIO

# OpenAI API í‚¤ ì„¤ì •
client = OpenAI(api_key=st.secrets["openai_api_key"])

# ChatGPT API í˜¸ì¶œ
def get_chatgpt_response(prompt):
    response = client.chat.completions.create(
        model="gpt-4o-mini",  # ì‚¬ìš©í•  ëª¨ë¸
        messages=[
            {"role": "system", "content": 
             '''
            ë„ˆëŠ” ì´ˆë“±í•™êµ ì˜ì–´êµì‚¬ì´ê³ , ë‚˜ëŠ” ì´ˆë“±í•™ìƒì´ì•¼. ë‚˜ì™€ ì˜ì–´ë¡œ ëŒ€í™”í•˜ëŠ” ì—°ìŠµì„ í•˜ê±°ë‚˜, ì˜ì–´ í‘œí˜„ì— ëŒ€í•œ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ëŒ€ë‹µì„ í•´ì¤˜. 
            ì˜ì–´ê³µë¶€ì™€ ê´€ê³„ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” ëŒ€ë‹µí•  ìˆ˜ ì—†ì–´. ë‚˜ì˜ ì˜ì–´ ìˆ˜ì¤€ì€ CEFR A1 ìˆ˜ì¤€ì´ì•¼. ì˜ì–´ë¡œ ëŒ€í™” í•  ë•Œ, ë‚˜ì—ê²Œ ë§ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ë§í•´ì¤˜.
             '''
             },
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content

# ìŒì„±ì„ ë…¹ìŒí•˜ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def record_and_transcribe():
    audio = audiorecorder("ë…¹ìŒ ì‹œì‘", "ë…¹ìŒ ì™„ë£Œ", pause_prompt="ì ê¹ ë©ˆì¶¤")
    
    if len(audio) > 0:
        st.success("ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤...")
        st.write("ë‚´ê°€ í•œ ë§ ë“£ê¸°")
        # To play audio in frontend:
        st.audio(audio.export().read()) 
        
        # ë…¹ìŒí•œ ì˜¤ë””ì˜¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        audio_file_path = Path("recorded_audio.wav")
        audio.export(str(audio_file_path), format="wav")

        # Whisper APIë¥¼ ì‚¬ìš©í•´ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        with open(audio_file_path, "rb") as audio_file:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
        return transcription.text
    
    return None

# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒí•˜ëŠ” í•¨ìˆ˜
def text_to_speech_openai(text):
    try:
        speech_file_path = Path("speech.mp3")
        response = client.audio.speech.create(
            model="tts-1",
            voice="shimmer",  # OpenAI TTS ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  ìŒì„±
            input=text
        )
        with open(speech_file_path, "wb") as f:
            f.write(response.content)  # ìŒì„± íŒŒì¼ì„ ì €ì¥
        st.write("ì¸ê³µì§€ëŠ¥ ì„ ìƒë‹˜ì˜ ëŒ€ë‹µ ë“£ê¸°")    
        st.audio(str(speech_file_path))  # ìŒì„±ì„ Streamlitì—ì„œ ì¬ìƒ
    except Exception as e:
        st.error(f"í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

# ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜
def display_messages():
    for message in st.session_state['chat_history']:
        if message['role'] == 'user':
            st.chat_message("user").write(message['content'])
        else:
            st.chat_message("assistant").write(message['content'])

# Streamlit UI

# ë©”ì¸ í™”ë©´ êµ¬ì„±
st.header("âœ¨ì¸ê³µì§€ëŠ¥ ì˜ì–´ ì„ ìƒë‹˜ ì‰ê¸€ë§ğŸ‘±ğŸ¾â€â™‚ï¸")
st.subheader("ğŸ˜ƒììœ ë¡­ê²Œ ëŒ€í™”í•˜ê¸°")
st.divider()

#í™•ì¥ ì„¤ëª…
with st.expander("â—â— ê¸€ìƒìë¥¼ í¼ì³ ì‚¬ìš©ë°©ë²•ì„ ì½ì–´ë³´ì„¸ìš” ğŸ‘†âœ…", expanded=False):
    st.markdown(
    """ 
    1ï¸âƒ£ [ë…¹ìŒ ì‹œì‘] ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‰ê¸€ë§ì—ê²Œ ë§í•˜ê¸°<br>
    2ï¸âƒ£ [ë…¹ìŒ ì™„ë£Œ] ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ë‚´ê°€ í•œ ë§ê³¼ ì‰ê¸€ë§ì˜ ëŒ€ë‹µ ë“¤ì–´ë³´ê¸°<br> 
    3ï¸âƒ£ [ë…¹ìŒ ì‹œì‘] ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ëŒ€ë‹µí•˜ê³  ì´ì–´ì„œ ë°”ë¡œ ì§ˆë¬¸í•˜ê¸°<br>
    4ï¸âƒ£ 1~3ë²ˆì„ ë°˜ë³µí•˜ê¸°. ë§ë¬¸ì´ ë§‰í ë• [ì ê¹ ë©ˆì¶¤] ë²„íŠ¼ì„ ëˆ„ë¥´ê¸°<br>
    <br>
    ğŸ™ ì‰ê¸€ë§ì€ ì™„ë²½í•˜ê²Œ ì´í•´í•˜ê±°ë‚˜ ì œëŒ€ë¡œ ëŒ€ë‹µí•˜ì§€ ì•Šì„ ìˆ˜ ìˆì–´ìš”.<br> 
    ğŸ™ ê·¸ëŸ´ ë•Œì—ëŠ” [ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ê¸°] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”
    """
    ,  unsafe_allow_html=True)
    st.divider()
    st.write("ğŸ”¸ì´ë²ˆ ë‹¨ì›ê³¼ ê´€ë ¨í•˜ì—¬ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³¼ ìˆ˜ ìˆì–´ìš”.") 
    st.write("ğŸ”¸ì˜ì–´ì— ëŒ€í•´ ì „ë°˜ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ì ì„ í•œêµ­ì–´ë‚˜ ì˜ì–´ ì¤‘ ì›í•˜ëŠ” ë§ë¡œ ì§ˆë¬¸í•´ë„ ë¼ìš”.")
    st.write("ğŸ”¸ì˜ì–´ë¡œ ì‰ê¸€ë§ê³¼ ììœ ë¡­ê²Œ ëŒ€í™”í•  ìˆ˜ë„ ìˆì–´ìš”.")

    
# ë²„íŠ¼ ë°°ì¹˜
col1, col2 = st.columns([1,1])

with col1:
    user_input_text = record_and_transcribe()
    if user_input_text:
        st.session_state['chat_history'].append({"role": "user", "content": user_input_text})
        response = get_chatgpt_response(user_input_text)
        if response:
            text_to_speech_openai(response)
            st.session_state['chat_history'].append({"role": "chatbot", "content": response})    

with col2:
    if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ê¸°", type="primary"):
        st.session_state['chat_history'] = []
        st.rerun()

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    # ë©”ì‹œì§€ í‘œì‹œ
    display_messages()
    
    #st.header(
        #'''

#'''
    #)
    #st.divider()





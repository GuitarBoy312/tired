import streamlit as st
from openai import OpenAI
import os
from pathlib import Path
from datetime import datetime
from audiorecorder import audiorecorder
from pydub import AudioSegment
import io

# OpenAI API í‚¤ ì„¤ì •
client = OpenAI(api_key=st.secrets["openai_api_key"])

# ChatGPT API í˜¸ì¶œ
def get_chatgpt_response(question):
    response = client.chat.completions.create(
        model="gpt-4o-mini",  # ì‚¬ìš©í•  ëª¨ë¸
        messages=[
            {"role": "system", "content": 
             '''
             ë„ˆëŠ” ì´ˆë“±í•™êµ ì˜ì–´êµì‚¬ì•¼. ë‚˜ëŠ” ì´ˆë“±í•™ìƒì´ê³ , ë‚˜ì™€ ì˜ì–´ë¡œ ëŒ€í™”í•˜ëŠ” ì—°ìŠµì„ í•´ ì¤˜. ì˜ì–´ê³µë¶€ì™€ ê´€ê³„ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” ëŒ€ë‹µí•  ìˆ˜ ì—†ì–´. ê·¸ë¦¬ê³  ë‚˜ëŠ” ë¬´ì¡°ê±´ ì˜ì–´ë¡œ ë§í• ê±°ì•¼. ë‹¤ë¥¸ ì–¸ì–´ë¡œ ì¸ì‹í•˜ì§€ ë§ì•„ì¤˜.            
[ëŒ€í™”ì˜ ì œëª©]
I'm Happy
[ì§€ì‹œ]
1. ë‚´ê°€ ë„ˆì—ê²Œ ê°ì •ì„ ë¬»ëŠ” ì§ˆë¬¸ì„ í• ê±°ì•¼. 
2. ë„ˆëŠ” ë‚´ ì§ˆë¬¸ì„ ë“£ê³  ì•„ë˜ì— ì£¼ì–´ì§„ ëŒ€ë‹µ ì¤‘ í•˜ë‚˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•´ì„œ ëŒ€ë‹µì„ í•´.
3. ê·¸ í›„, ë„ˆëŠ” ì§ˆë¬¸ì„ ë§í•´. ì§ˆë¬¸ì„ í•  ë•Œ ì•„ë˜ì— ì£¼ì–´ì§„ ê°ì • ì¤‘ í•˜ë‚˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ê³¨ë¼ì„œ ì§ˆë¬¸í•˜ë©´ ë¼. ë‚´ê°€ ë¬´ìŠ¨ ëŒ€ë‹µì„ í•˜ë“  ë‹¤ìŒë²ˆì—ëŠ” ë‹¤ë¥¸ ê°ì •ì„ ì„ íƒí•´ì„œ ë¬¼ì–´ë´.
4. ë‚´ê°€ ê·¸ë§Œí•˜ìê³  í•  ë•Œê¹Œì§€ ê³„ì† ì£¼ê³  ë°›ìœ¼ë©° ëŒ€í™”í•˜ì.
[ì§ˆë¬¸]
- Are you â€¦.?
[ëŒ€ë‹µ]
- Yes, I am
- No, I'm not
[ê°ì •ì˜ ì¢…ë¥˜]
- happy
- sad
- angry
- hungry
- thirsty
- tired
             '''
             },
            {"role": "user", "content": question}
        ]
    )
    return response.choices[0].message.content
# ìŒì„±ì„ ë…¹ìŒí•˜ëŠ” í•¨ìˆ˜
def record_and_transcribe():
    audio = audiorecorder("í´ë¦­í•˜ì—¬ ë…¹ìŒí•˜ê¸°", "ë…¹ìŒì¤‘...í´ë¦­í•˜ì—¬ ì €ì¥í•˜ê¸°")
    if len(audio) > 0:
        audio.export("recorded_audio.wav", format="wav")

    
    #recognizer = sr.Recognizer()
    #with sr.Microphone() as source:
        #st.info("ìŒì„±ì„ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤. ë§ì„ ì‹œì‘í•˜ì„¸ìš”...")
        #audio = recognizer.listen(source)
        #st.success("ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤...")
        #audio_bytes = io.BytesIO(audio.export().read())
        #audio_segment = AudioSegment.from_file(audio_bytes, format="mp3")
        # ë…¹ìŒí•œ ì˜¤ë””ì˜¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        audio_file_path = Path("recorded_audio.wav")
        with open(audio_file_path, "wb") as f:
            f.write(audio.get_wav_data())

        # Whisper APIë¥¼ ì‚¬ìš©í•´ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        with open(audio_file_path, "rb") as audio_file:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
        return transcription.text
# STT í•¨ìˆ˜
#def STT(audio):
    # íŒŒì¼ ì €ì¥
    #filename = 'input.mp3'
    #audio.export(filename, format="mp3")
    
    # ìŒì› íŒŒì¼ ì—´ê¸°
    #with open(filename, "rb") as audio_file:
        # Whisper ëª¨ë¸ì„ í™œìš©í•´ í…ìŠ¤íŠ¸ ì–»ê¸°
        #transcript = client.audio.transcriptions.create(model="whisper-1", file=audio_file)
    
    # íŒŒì¼ ì‚­ì œ
    #os.remove(filename)
    
    #return transcript.text

# Streamlit UI

# ë©”ì¸ í™”ë©´ êµ¬ì„±
st.title("âœ¨ì¸ê³µì§€ëŠ¥ ì˜ì–´ ì„ ìƒë‹˜ğŸ‘±ğŸ¾â€â™‚ï¸")
st.subheader("ê°ì •ì— ëŒ€í•œ ëŒ€í™”í•˜ê¸°")
st.divider()

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

# ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜
def display_messages():
    for message in st.session_state['chat_history']:
        if message['role'] == 'user':
            st.chat_message("user").write(message['content'])
        else:
            st.chat_message("assistant").write(message['content'])
# ë²„íŠ¼ ë°°ì¹˜
col1, col2 = st.columns([1,1])

with col1:
    if st.button("ëª©ì†Œë¦¬ë¡œ ëŒ€í™”í•˜ê¸°", use_container_width=True): 
        user_input_text = record_and_transcribe()
        if user_input_text:
            st.session_state['chat_history'].append({"role": "user", "content": user_input_text})
            response = get_chatgpt_response(user_input_text)
            if response:
                text_to_speech_openai(response)
                st.session_state['chat_history'].append({"role": "chatbot", "content": response})    
   
with col2:
    if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œí•˜ê¸°",type="primary"):
        st.session_state['chat_history'] = []
        st.rerun()
        
# ê¸°ëŠ¥ êµ¬í˜„ ê³µê°„
#col1, col2 = st.columns(2)
#with col1:
    # ì™¼ìª½ ì˜ì—­ ì‘ì„±
    #st.subheader("ì§ˆë¬¸í•˜ê¸°")
    # ìŒì„± ë…¹ìŒ ì•„ì´ì½˜ ì¶”ê°€
    #audio = audiorecorder("í´ë¦­í•˜ì—¬ ë…¹ìŒí•˜ê¸°", "ë…¹ìŒì¤‘...í´ë¦­í•˜ì—¬ ì €ì¥í•˜ê¸°")
    #if (audio.duration_seconds > 0) and (st.session_state.get("check_reset", False) == False):
        # ìŒì„± ì¬ìƒ 
        #st.audio(audio.export().read())
        # ìŒì› íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        #audio_bytes = io.BytesIO(audio.export().read())
        #audio_segment = AudioSegment.from_file(audio_bytes, format="mp3")
        #question = STT(audio_segment)

        # ì±„íŒ…ì„ ì‹œê°í™”í•˜ê¸° ìœ„í•´ ì§ˆë¬¸ ë‚´ìš© ì €ì¥
        #now = datetime.now().strftime("%H:%M")
        #st.session_state["chat"] = st.session_state.get("chat", []) + [("user", now, question)]
        # GPT ëª¨ë¸ì— ë„£ì„ í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„í•´ ì§ˆë¬¸ ë‚´ìš© ì €ì¥
        #st.session_state["messages"] = st.session_state.get("messages", []) + [{"role": "user", "content": question}]
        #response = get_chatgpt_response(question)
        #if response:
            #st.session_state["chat"] = st.session_state["chat"] + [("chatbot", now, response)]
            #st.session_state["messages"] = st.session_state["messages"] + [{"role": "assistant", "content": response}]

# ë©”ì‹œì§€ í‘œì‹œ
display_messages()

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.header(
        '''
ì‚¬ìš©ë°©ë²•
1. 'ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ íŒŒë€ìƒ‰ì´ í™œì„±í™”ë˜ë©´ ì¸ê³µì§€ëŠ¥ ì„ ìƒë‹˜ì—ê²Œ ì§ˆë¬¸í•˜ê¸°
2. ì¬ìƒë²„íŠ¼(ì„¸ëª¨)ë¥¼ ëˆŒëŸ¬ ì„ ìƒë‹˜ì˜ ëŒ€ë‹µì„ ë“£ê¸°
3. 'ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ íŒŒë€ìƒ‰ì´ í™œì„±í™”ë˜ë©´ ëŒ€ë‹µí•˜ê³  ë°”ë¡œ ì§ˆë¬¸í•˜ê¸°
'''
    )
    st.divider()

    st.subheader("ë‹¤ìŒ ë³´ê¸° ì¤‘ ê³¨ë¼ì„œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”")
    st.markdown("1ï¸âƒ£ Are you happy?<br>2ï¸âƒ£ Are you sad?<br>3ï¸âƒ£ Are you angry?<br>4ï¸âƒ£ Are you hungry?<br>5ï¸âƒ£ Are you thirsty?<br>6ï¸âƒ£ Are you tired?", unsafe_allow_html=True)

    st.divider()

    st.subheader("ì„ ìƒë‹˜ì˜ ì§ˆë¬¸ì„ ë“£ê³ , ë‹¤ìŒ ë³´ê¸° ì¤‘ ê³¨ë¼ì„œ ëŒ€ë‹µí•´ ë³´ì„¸ìš”.")
    st.markdown("1ï¸âƒ£ Yes, I am.<br>2ï¸âƒ£ No, I'm not.", unsafe_allow_html=True)
